Нужно спроектировать систему, которая в ответ на запрос пользователя выведет ему
наиболее релевантные этому запросу видеоролики.

1. Выяснение требований:

* Система на вход принимает только текстовые запросы
* На платформе размещается только видео
* Релевантность видео определяется заголовком, описанием и визуальным содержанием
* Для обучения доступные 10 млн. пар в формате ⟨видео, текстовый запрос⟩
* Система моноязычная
* Всего в системе 1 млрд. роликов
* Так как мы проектируем поисковую систему, то считаем, что персонализация не нужна

Резюмируя требования: 

Нужно спроектировать систему для поиска, выдающую релевантные результаты
Чтобы выполнять поиск будут использоваться признаки из видео и текстовые описания

2. Формулировка проблемы как задачи машинного обучения

* Цель: в ответ на текстовый корпус выдать список видеороликов, отсортированных по релевантности
* Определение входных и выходных данных: система поиска принимает на вход текстовый запрос и выдает список видеороликов, отсортированных по релевантности этому запросу.
* Выходные данные модели: отранжированный список видеороликов.

3. Подготовка данных.

* Конструирование данных: алгоритмы машинного обучения работают с числовыми признаками, соотвественно текст и видео нужно преобразовать в эмбединги.
 * Текст обычно проходит через базовый пайплайн: нормализуем текст, токенизируем текст, преобразуем лексемы в идентификаторы или хешируем.
 * Видео проходит через следующий пайплайн: декодируем кадры; выбираем ключевые кадры; изменение размеров; масштабирование, нормализация и коррекция цветового режима.

4. Разработка модели.

* Текст
 * BoW и TF-IDF работают быстро, но не учитываю позиции слов, семантику, их нужно часто пересчитывать
 * Word2vec и трансформеры: на w2v можно строить хорошие представления для слов, а так же неглубокие нейронные сети, для предсказания контекста ( CBOW, SkipGram ); трансформеры учитывают как позиции, так и семантику. Являются крайне эффективным инструментом для работы с текстовыми корпусами.
* Для работы с видео есть два основных подхода: модели на уровне видео и модели на уровне кадра.
 * Модель на уровне видео работает на 3D свертках или на трансформерах. Требуется много ресурсов
 * Модель на уровне кадров: предварительная обработка, формирование кадров, создание эмбедингов по этим кадрам, агрегация. Таким образом получаем эмбединг видео.

* Для обучения буду использовать контрастное обучени, подойдет или триплетлосс или кроссэнтропия

5. Оценка.

* Оффлайн метрики:
 * precision@k, recall@k, MRR

* Онлайн метрики:
 * CTR, процент досмотра до конца, общее время просмотра видео из поисковой выдачи

6. Эксплуатация.
В режиме эксплуатации система выводит ранжированный список видеороликов, релевантных заданному текстовому запросу.
* Предсказательный пайплайн:
 * Визуальный поиск
  * Кодируем текст, ищем среди эмбедингов видео самые похожие k-эмбедингов
 * Текстовый поиск
  * Используем или elasticsearch ( обратный индекс ) или текстовый энкодер и ищем по VDB
 * Слой слияния
  * Принимает на вход два списка полученных видеороликов, которые были получены на предыдущих шагах, и объединяет их в новый список
   * Простейший способ -- повторно ранжировать видео на основании взвешенной суммы их предсказанных показателей релевантности.
   * Более сложный подход -- внедрить дополнительную модель для повторного ранжирования видео; он требует больших затрат из-за того, что модель нужно обучать. + снижается скорость инференса.
 * Сервис повторного ранжирования изменяет ранжированный список видеороликов, применяя бизнес-логику и политики.


Important links:
* https://arxiv.org/pdf/2012.04124
* https://www.linkedin.com/pulse/ai-query-understanding-daniel-tunkelang/
* https://arxiv.org/pdf/2005.07356
* https://arxiv.org/pdf/2107.00676
