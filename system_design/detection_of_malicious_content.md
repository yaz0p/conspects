Нарушения этических принципов можно разделить на две категории:
- Вредоносный контент: призывы к насилию, непристойные изображения, демонстрация самоповреждения, разжигание ненависти и т. д.
- Вредоносные действия и участники: фиктивные учетные записи, спам, фишинг, организованный троллинг и другое опасное поведение.

Нужно спроектировать систему, которая активно отслеживает новые посты и выявляет контент, нарушающий правила платформы, после чего удаляет его или понижает его приоритет. 
Как референс были выбраны: Facebook, Twitter, LinkedIn.

1. Выяснение требований:

* Система должна обнаруживать вредносный контент
* Система должна обнаруживать вредоносный контент на разных языках
* Под вредоносный контент подходят следующие категории: насилие, нагота, разжигание ненависти, дезинформация
* Ручная разметка в количестве 10_000 шт. в день
* Пользователи могут сообщать о вредоносном контенте, который они заметили
* Модель должна быть интерпретируемой: при удалении контента нужно сообщать по какой причине он был удален
* Скорость работы сервиса различна для различных тем: насилие нужно удалять мгновенно, в то время как остальные темы могут находиться в отложенной выборке.

Резюмирую требования:

Нужно спроектировать систему для детекции вредоносного контента, которая выявляет вредоносные посты, а затем удаляет их или понижает их приоритет, сообщая пользователю, почему она сочла пост вредоносным. 
Содержимым поста может быть текст, изображения, видео или их произвольное сочетание, и контент может создаваться на разных языках. 
У пользователей есть возможность сообщать о вредоносных постах.

2. Формулировка проблемы как задачи машинного обучения

* Цель: с высокой точностью предсказывать вредоносные посты.
* Определение входных и выходных данных: система принимает на вход пост и возвращает вероятность того, что он является вредоносным. Информация мультимодальна ( текст, видео, аудио, изображения ). Чтобы делать точные предсказания, система должна учитывать все модальности. Для объединения разнородных данных часто применяются два метода слияния: позднее слияние и раннее слияние.
- При позднем слиянии разные виды данных обрабатываются независимо друг от друга, а потом полученные вероятности объединяются, чтобы получить финальное предсказание. У такого подхода есть недостатки: нужно обучать модели для различных модальностей, а это большие затраты, а во вторых комбинация модальностей может оказаться зловредной, хотя каждая модальность по отдельности является безвредной, например, мемы.
- При раннем слиянии модальности сначала объединяются, а затем модель делает предсказание. При таком подходе не требуется собирать обучающие данные отдельно для каждой модальности, а также анализируются все модельности. Такую модель сложнее обучить.
* Выходные данные модели: класс поста

3. Подготовка данных.

* Доступны следующие данные: пользователи, посты, взаимодействия пользователей с постами.
* Пользователь хранит информацию о: ID пользователя, Имя пользователя, Возраст, Пол, Город, Страна, Электронная почта
* Пост хранит информацию о ( обычно присутствуют сотни признаков, но я вынес несколько для наглядности ): ID поста, ID автора, IP-адрес, временная метка, текстовое содержимое, изображения или видео, ссылки
* Взаимодействия пользователей с постами хранят информацию о: ID пользователя, ID поста, Тип взаимодействия, Значение взаимодействия, Временная метка
* Конструирование признаков: пост может содержать информацию о: текстовое содержание, изображение или видео, реакции пользователей, автор, контекстная информация.
 - Текстовое содержание: извлекать необходимые признаки из текста можно при помощи DistilBert, BGE M3 и прочих энкодеров.
 - Изображение или видео: извлекать признаки можно в два этапа: предобработка, включающая в себя декодирование, изменение размеров и нормализация; выделение признаков из полученных признаков можно при помощи CNN или трансформеров, например, CLIP, BLIP, SimCLR, VideoMoCo, LLaVa, Vicuna, etc.
 - Реакции пользователей на пост: является ли пост вредоносным, можно также определить на основании реакций пользователей, особенно если его содержимое неоднозначно. Поскольку реакции пользователей эффективно помогают обнаруживать вредоносный контент, рассмотрим некоторые признаки, которые можно сконструировать на их основе. 

Количество лайков, репостов, комментариев и жалоб. Обычно эти числовые значения масштабируются, чтобы модель быстрее сходилась в процессе обучения.

Комментарии. Комментарии могут помочь выявить вредоносный контент. Чтобы подготовить признаки, комментарии нужно преобразовать в числовые представления:
с помощью предварительно обученной модели, которая уже применялась ранее, получить эмбеддинг каждого комментария;
агрегировать (например, усреднить) эмбеддинги, чтобы получить итоговый эмбеддинг.

Признаки автора. Прошлая активность автора тоже помогает определить, является ли пост вредоносным.Список признаков будет описан ниже:

- История нарушений автора:

Количество нарушений. 
Числовое значение: сколько раз автор раньше нарушал правила площадки.

Общее количество жалоб от пользователей.
Числовое значение: количество жалоб на посты автора.

Доля ненормативной лексики.
Числовое значение: доля нецензурных слов в предыдущих постах и комментариях автора. Чтобы выявлять такие слова, можно воспользоваться готовым списком нецензурных слов.

- Демографические данные автора:
Возраст.
Возраст пользователя — один из самых важных предсказательных признаков.

Пол. 
Категориальный признак, представляющий пол пользователя. Чтобы представить пол, мы будем использовать унитарное кодирование.

Город и страна.
Эти признаки могут принимать множество разных значений. Чтобы их представить, мы воспользуемся слоем эмбеддингов, который преобразовывает город и страну в векторы признаков. Обратите внимание, что унитарное кодирование — не самый эффективный способ представить страну и город, потому что представления получаются слишком длинными и разреженными.

- Информация об учетной записи:
Количество подписчиков и подписок.

Возраст учетной записи.
Числовое значение: срок существования учетной записи автора. Это предсказательный признак, потому что недавно созданные учетные записи с большей вероятностью рассылают спам или нарушают правила.

- Контекстная информация
Время суток.
Время, в которое автор создал пост. В нашем примере время будет разбиваться на категории (утро, день, вечер или ночь), и этот признак будет представляться с помощью унитарного кодирования.

Устройство.
Устройство, которое использует автор, — например, смартфон или ПК. Для представления этого признака тоже будет использоваться унитарное кодирование.

4. Разработка модели.

* При выборе модели необходимо выбрать нужную архитектуру и подобрать гиперпараметры ( скрытые уровни, функция активации, скорость обучения etc. ). Для подобра гиперпараметров используют grid search или random search. Можно посмотреть в сторону optuna.
* При составлении датасета у нас есть ручная разметка и автоматическая разметка. Ручная разметка дорогостоящая, но качественная; авторазметка состоит из жалоб пользователей и в ней много шума. При валидации будет использоваться ручная разметка, а для обучения будет использоваться автоматическая разметка.
* В качестве функции потерь выбирается кроссэнтропия. У мультимодальных систем есть проблема с переобучением. Для её решния прибегают к фокальной функции потерь и градиентному блендинг ( см. важные ссылки )

5. Оценка.

* Оффлайн метрики:
 *  PR-кривая, ROC-кривая, ROC-AUC; в нашем случае будет использоваться ROC-AUC.
* Онлайн метрики:
 * Распространенность. Отношение количества вредоносных постов, которые система не обнаружила, к общему количеству постов на платформе.
 * Показы вредоносного контента. Мы отдаем предпочтение этой метрике перед распространенностью. Дело в том, что количество вредоносных постов на платформе не показывает, скольких людей затронули эти посты, тогда как количество показов вредоносного контента отражает эту информацию.
 * Доля успешных обжалований. Доля постов, которые были сочтены вредоносными, но разблокированы в результате обжалования.
 * Доля профилактических вмешательств. Доля вредоносных постов, которые система обнаружила и удалила до того, как пользователи пожаловались на них.
 * Количество жалоб пользователей на вредоносные сообщения отдельных классов. Эта метрика оценивает качество системы по количеству жалоб пользователей на сообщения, относящиеся к каждому отдельному классу вредоносного контента.

6. Экплуатация.

Эксплуатация всей системы включает в себя несколько сервисов: сервис обнаружения вредносного контента, сервис обработки нарушений, сервис понижения приоритета.

* Пайплайн эксплуатации:

 * Сервис обнаружения вредоносного контента:
  * Для нового поста этот сервис предсказывает вероятность того, что пост является вредоносным. Согласно требованиям, некоторые особо опасные типы вредоносного контента нужно обрабатывать немедленно. В таких случаях сервис обработки нарушений безотлагательно удаляет пост.
 * Сервис обработки нарушений:
  * Сервис обработки нарушений немедленно удаляет пост, если сервис обнаружения вредоносного контента предсказывает вредоносность с высокой достоверностью. Он также сообщает пользователю, почему пост был удален
 * Сервис понижения приоритета
  * Когда сервис обнаружения вредоносного контента предсказывает вредоносность с низкой достоверностью, сервис понижения приоритета временно деприоритизирует пост, чтобы он менее активно распространялся среди пользователей. Затем пост помещается в хранилище для ручной обработки. Модераторы вручную проверяют пост и помечают его одним из предварительно определенных классов вредоносного контента. Эти посты с метками будут использоваться на последующих итерациях обучения, чтобы улучшить модель.

Important links:
* https://ai.meta.com/blog/community-standards-report/
* https://forums.fast.ai/t/gradient-blending-for-multi-modal-models-in-progress/75645
* https://paperswithcode.com/method/focal-loss
* https://arxiv.org/pdf/2107.00676
* https://machinelearningmastery.com/roc-curves-and-precision-recall-curves-for-classification-in-python/
* https://labelyourdata.com/articles/bias-in-machine-learning
* https://ai.meta.com/blog/harmful-content-can-evolve-quickly-our-new-ai-system-adapts-to-tackle-it/
* https://arxiv.org/pdf/2002.07917
* https://www.youtube.com/watch?v=YeX4MdU0JNk
* https://transparency.meta.com/ru-ru/features/approach-to-ranking/content-distribution-guidelines/content-borderline-to-the-community-standards/
* https://about.fb.com/news/2021/12/metas-new-ai-system-tackles-harmful-content/
* https://ai.meta.com/blog/how-facebook-uses-super-efficient-ai-models-to-detect-hate-speech/

